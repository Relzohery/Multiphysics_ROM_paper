% Title:    A LaTeX Template For Responses To a Referees' Reports
% Author:   Petr Zemek <s3rvac@gmail.com>
% Homepage: https://blog.petrzemek.net/2016/07/17/latex-template-for-responses-to-referees-reports/
% License:  CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/)
\documentclass[10pt]{article}

% Allow Unicode input (alternatively, you can use XeLaTeX or LuaLaTeX)
\usepackage[utf8]{inputenc}
\usepackage{xcolor}

\usepackage{microtype,xparse,tcolorbox}
\newenvironment{reviewer-comment }{}{}
\tcbuselibrary{skins}
\tcolorboxenvironment{reviewer-comment }{empty,
  left = 1em, top = 1ex, bottom = 1ex,
  borderline west = {2pt} {0pt} {black!20},
}
\ExplSyntaxOn
\NewDocumentEnvironment {response} { +m O{black!20} } {
  \IfValueT {#1} {
    \begin{reviewer-comment~}
      \setlength\parindent{2em}
      \noindent
      \ttfamily #1
    \end{reviewer-comment~}
  }
  \par\noindent\ignorespaces
} { \bigskip\par }

\NewDocumentCommand \Reviewer { m } {
  \section*{Comments~by~Reviewer~#1}
}
\ExplSyntaxOff
\AtBeginDocument{\maketitle\thispagestyle{empty}\noindent}

\title{Statement on the Revision of ANUCENE-D-22-00268 \\
  Based on the Referees' Report}
\author{Rabab Elzohery \and Jeremy A. Roberts}
\date{\today}

\begin{document}
This statement concerns our revision of the ANUCENE-D-21-00065, entitled ``Modeling Neutronic Transients with Galerkin Projection onto a Greedy-Sampled, POD Subspace'', based on the referees' report.

\Reviewer{\#1}

\begin{response}{
   The novelty of the paper is then restricted to the implementation of the model in a specific code, and to its application to a specific problem. I believe this may still make it worth publishing, but the authors are requested to rewrite abstract, introduction and conclusions in order to:
   - acknowledge the work of other authors on the subject
   - adapt their claims to the fact that the methodology has already been proposed and tested.
   They should also change the title, as it gives the idea that this is a first-of-a-kind paper using a POD-Galerkin and DEIM for neutronics, while this is not the case. The title should focus on elements of actual novelty (implementation in a specific code and application to a benchmark).
}
  These are all great and valid questions. Here are the answers and some clarifications:
  \begin{itemize}
  \item{The greedy sampling can treat high-dimensional input spaces,  but we expect that this will lead to an increase in the number of selected samples that contribute to the POD-greedy space.}
  
 \item{The unscented transform and the POD-greedy sampling are fundamentally different in scope.
  In the context of uncertainty quantification, the unscented transform can be used to select parameter samples that could represent the entire parameter space.
  As presented in the suggested paper,  the method seems to be promising and efficient when input  parameters are correlated and their covariance matrix is available or computable.
  On the other hand, the greedy-POD sampling is used to construct a parametric ROM by building  a global POD space that can capture variation in the parameters domain. These  parameters do not have to be correlated or follow a specific distribution. 
  In this work, our main goal  was to develop a parametric ROM based on the Galerkin projection method. The same framework implemented here can be used to perform design optimization or sensitivity study where  there is only one parameter that is perturbed,  e.g, control rod position and  initial condition.
  
  We agree that this was not clear in the paper, accordingly we have emphasized this in the introduction section.}
  
  \item{Regarding the training data size, note that out of the 50 samples, only 20 were chosen since the algorithm was terminated based on the set criteria.
  It is true that the ROM was evaluated 50 times to obtain the reference solution and to compute the error based on which a new sample is selected.  
  However, as mentioned in our concluding remarks, work is ongoing to develop a posterior error indicator. This posterior error (estimate) wonâ€™t require running the FOM for the entire parameter training set.
  	 
  Using this error indicator, the worst sample will be selected and the FOM will be evaluated for this sample only. 
  Also, we expect that this might lead to faster convergence of the greedy space since it will be more convienent to generate larger parameter sample size.
  For more details, you may look at Remark-2.47 in Ref.[12].}
  \item{We agree that 100 samples are not enough but our goal here is to illustrate the method not to quantify the real uncertainty. So, we think that as long as the same number of samples is used in the two models, the comparison is fair.
  \item To conclude, the goal here is to develop an efficient parametric ROM not an efficient UQ method.}
  \end{itemize}

\end{response}

\begin{response}{ would not define JFNK as a modern method. I have found publications from the eighties on it, and I guess it may be older than that. I also would avoid passing the message that block-matrix coupling is faster than operator-splitting. Very often, this is not the case, as operator splitting allows a very well targeted preconditioning, and selective solution of non-converged fields
   }

  

\end{response}

\begin{response}{
 In the sentence "The initial condition for the transient was computed by solving the steady-state equation", I believe it would be more accurate to speak about "eigenvalue problem" instead of " steady-state equation".}

We agree with the reviewer and this has beem modified.

\end{response}

\begin{response}{The authors mention "Note that at each time step the fast absorption cross section is a function of the solution itself". Is this an assumption, a statement, or a feature of the benchmark? Is this the only XS that is parametrized?.}
		
This a feature of the benchmark. The fast corss section is defined as a function of the temerature at each time step. And the temperature changes as a function of the neutron flux, i.e, the solution.
\end{response}

\begin{response}
  {What do you mean by "This reference solution is not necessarily numerically converged in either space or time". If it is not converged, it may not be a meaningful solution and should probably not be used in a numerical benchmark, since it may not be representative of the problem at hand. Please clarify.}
  ----------------------------------------
	
\end{response}

\begin{response}
	{ I am not sure I understand how the snapshots are taken. Are they the time dependent fluxes taken from the FOM solution? If that is the case, results in fig. 6 are essentially a sanity check, since reaching that level of accuracy would always require precomputing the transient with the FOM model. Please clarify}
	
	Yes, the snapshots are FOM time-dependent flux. In Fig.6 shows the error between two ROMs.
	One with using a direct-projection of the operator, and the other with approximating the operator with MDEIM (i.e, no direct projection). The former model is considered as the reference in this case.
	
	
	
------------------------------------
\end{response}

\begin{response}
 {How are the parameters points sampled in section 4.2.2}
 
 They are sampled from the normal distribution shown in table~4. No correlation was assumed between the six parameters.

\end{response}

\begin{response}
{I find it very difficult to interpret the results of section 4.2.2. The authors compare the predictions of ROM and FOM, but what is the impact of the parameters on the FOM itself? Without this information, it is impossible to assess the goodness of the ROM approximation. The error made by the ROM model should be small with respect to the differences expected in the FOM when changing the selected parameters.}

We mentioned that the time-to-peak differs from sample to another in the FOM solution, 
because the value of beta differs between samples.
On the other hand, the time-to-peak of the ROM solution is in exact agreement with the FOM solution,
We view each parameter point as a different problem with a different solution, and we are comparing this solution to the one obtained from the ROM.
------------------------------------
\end{response}

\Reviewer{\#2}
\begin{response}
	{
		Equations (14)-(15), (18)-(20):
		In my understanding, the non-linear operator L is calculated with the MDEIM, and the authors also applied the POD for Equation (14) to treat the temperature distribution with fewer DOFs.
		However, I could not clearly understand how the authors calculate Equation (15) before applying MDEIM from the expansion coefficients $(a_T)$ for the temperature distribution. A few more descriptions of the procedure will help a better understanding for readers.
		( I mean the relationship between the non-linear operator L and f(y(t)) in section 2.2 is not clear. The description of Equation (12) also makes it difficult to clearly understand because Equation (12) can be seen as a linear equation but the actual operator L is a non-linear function due to the feedback effect.)
	}

f(y(t)) was mentioned in section 2 to motivate the use of DEIM in general. In the problem tackled here, there is no such f(y(t)). MDEIM was used to approximate the problem non-linear operator.
The At each time step, MDEIM is used and the eq solved for the flux coefficients. Theses flux coefficient are then used in eq. 20 to update the temperature coefficients $a-T$, which is the ROM approximation of eq. 14.
Using this computed temperature, the fast cross-section is updated using eq. 15.
But we agree with reviewer that eq.12, as presented, is linear 


\end{response}

-------------------------------


\begin{response}
{ pages 15 and Table 1:
	The Doppler feedback coefficient, $3.034x10^-3 K^-0.5$, seems not identical to the benchmark specification in the reference [15]. In the original benchmark specification, it would be $2.034x10^-3 K^-0.5$.
	In addition, the axial bucking $(B^2)$ is specified in the original LRA 2D benchmark problem in my understanding. If the authors are using axial buckling, it should be described in Table 1. "nu" value is also missing in Table 1.
	(You can also find the LRA benchmark results calculated with the conventional codes in the following reference:
	T.M. Sutton, and B. N. Aviles, "Diffusion Theory Methods for Spatial Kinetics Calculations", Prog. Nucl. Energy, 30(2), 119-182, 1996.
	Since the initial keff = 0.9975 is a little higher than their results, I wonder whether the axial buckling is taken into account or not.)
	Off course, the above inconsistency in the FOM calculation condition does not affect the validity of the methodology presented in this work.}


The doppler coefficient .....
The axial buckling was accounted for as given on the benchmark documentation. We have commented on that in the paper and added it value in table 1 along with the value of $\nu$. Thanks for the catch.
Regarding to the value of initial keff, it is sensitive to the spatial discretization, the numerical solver and the convergence criteria, and this might be the cause of this little bias that you observed.
We agree with the reviewer that any inconsistency resulting from a change in the problem data from that in the original benchmark does not affect the presented results, as long the problem parameters are consistent in both the FOM and the ROM. 


-------------------------------------
\end{response}

\begin{response}
{
 page 1, line 11 : "ROM" --> reduced order model (ROM)
 page 12, Equation (11) : P --> I (Authors are using "I" for the number of precursor groups in page 13.)}
% page 15 : kappa = $3.204 x 10^-11 W/fission --> kappa = 3.204 x 10^-11 J/fission$
% page 18, line 2 : $fai(t)2 --> fai_2(t)}$

\end{response}
These have been corrected. Thanks for the catch.

\end{document}
